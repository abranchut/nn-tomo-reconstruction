{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A script to reconstruct a MOF particle from a subset of 8 projections from HSH75-Pd-HAADF_hdr0.ali (this code works for .mrc and .ali files), which originally is a stack of 29 projections between -70° and 70°.\n",
    "\n",
    "For an introduction on Python classes, see tutorial_classes.ipynb.\n",
    "For an introduction on how neural networks works, see https://www.3blue1brown.com/topics/neural-networks.\n",
    "For more details about the training procedure and the overall pytorch framework, see https://pytorch.org/tutorials/beginner/basics/intro.html.\n",
    "\n",
    "For more details about a particular function / method, see the specific documentation in the code.\n",
    "\n",
    "For more details about NN-FBP implementation, see the original article: Fast Tomographic Reconstruction from Limited Data Using Artificial Neural\n",
    "Networks, D. M. Pelt and al., 2013 (https://ieeexplore.ieee.org/document/6607157)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports ###\n",
    "from nntomo.utilities import get_MSE_loss\n",
    "from nntomo.network import nnfbp_training\n",
    "from nntomo.nnfbp import DatasetNNFBP\n",
    "from nntomo.projection_stack import ProjectionStack\n",
    "from nntomo.volume import Volume\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "The original 29 projections from STEM measurements. The         A subset of 8 projections: a comparison will be made between\n",
    "SIRT reconstruction using all these projections will be         the NN-FBP and the SIRT reconstructions to evaluate the\n",
    "used as a reference for the real volume of the particule.       reconstruction performance for very small subsets of projections.\n",
    "\n",
    "<img src=\"data/gifs/particule_29proj.gif\" width=\"300\"/>                                  <img src=\"data/gifs/particule_8proj.gif\" width=\"300\"/>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, a stack of ellipses and its associated projections are used for the training dataset. The training dataset is used to modify the values of the weights and biases of the network, by comparing the predicted output of each input of the dataset and the real outputs. The projections are made with the ASTRA toolbox. The corresponding dataset is created and saved. See the pytorch tutorial for more information about the use of Dataset objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation of the ellipses: [████████████████████████████████████████████████████████████] 100/100 Est wait 00:0.0\n",
      "\n",
      "Saving volume...\n",
      "File saved at c:\\Users\\Admin-tomo\\Documents\\tomo-reconstruction-alix\\github_repository\\nn-tomo-reconstruction\\scripts\\data\\volume_files\\rand7ellipses1024.mrc.\n",
      " ID: rand7ellipses1024\n"
     ]
    }
   ],
   "source": [
    "# Generation of the ellipses\n",
    "ellipses_volume = Volume.stack_7ellipses(100, shape=1024, semi_axis_range=(20,200), padding=100)\n",
    "ellipses_volume.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset...\n",
      "File saved at c:\\Users\\Admin-tomo\\Documents\\tomo-reconstruction-alix\\github_repository\\nn-tomo-reconstruction\\scripts\\data\\datasets_files\\nnfbp[rand7ellipses1024-full9th][rand7ellipses1024]bin.pickle.\n",
      " ID: nnfbp[rand7ellipses1024-full9th][rand7ellipses1024]bin\n"
     ]
    }
   ],
   "source": [
    "# Creation of a volume object for the ellipses\n",
    "ellipses_volume = Volume.retrieve('rand7ellipses1024')\n",
    "\n",
    "# Creation of the projections (9 projections from -90° to 70°)\n",
    "ellipses_projections = ProjectionStack.from_volume(ellipses_volume, 9, 'full')\n",
    "\n",
    "# Creation of the dataset for the neural network training:\n",
    "training_dataset = DatasetNNFBP(ellipses_projections, ellipses_volume)\n",
    "\n",
    "# Saving of the dataset:\n",
    "training_dataset.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Each slice of the ellipses stack:                          The 9 projections taken around the axis perpendicular to the screen:\n",
    "\n",
    "<img src=\"data/gifs/ellipses.gif\" width=\"300\"/>              <img src=\"data/gifs/ellipses_proj.gif\" width=\"800\"/>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, random spheres are used for the validation set. The validation set is used to assess the performance of the network during the training phase on unknown data, and decide when to stop the training to avoid overfitting. The projections are also made with the ASTRA toolbox. The corresponding dataset is created and saved. See the pytorch tutorial for more information about the use of Dataset objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation of the spheres: [████████████████████████████████████████████████████████████] 60/60 Est wait 00:0.04\n",
      "\n",
      "Saving volume...\n",
      "File saved at c:\\Users\\Admin-tomo\\Documents\\tomo-reconstruction-alix\\github_repository\\nn-tomo-reconstruction\\scripts\\data\\volume_files\\randspheres1024.mrc.\n",
      " ID: randspheres1024\n"
     ]
    }
   ],
   "source": [
    "# Generation of the spheres\n",
    "spheres = Volume.random_spheres(60, shape=1024, radius_range=(5,100), padding=50)\n",
    "spheres.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset...\n",
      "File saved at c:\\Users\\Admin-tomo\\Documents\\tomo-reconstruction-alix\\github_repository\\nn-tomo-reconstruction\\scripts\\data\\datasets_files\\nnfbp[randspheres1024-full9th][randspheres1024]bin.pickle.\n",
      " ID: nnfbp[randspheres1024-full9th][randspheres1024]bin\n"
     ]
    }
   ],
   "source": [
    "# Creation of a volume object for the spheres\n",
    "spheres = Volume.retrieve('randspheres1024')\n",
    "\n",
    "# Creation of the projections (9 projections from -90° to 70°)\n",
    "spheres_projections = ProjectionStack.from_volume(spheres, 9, 'full')\n",
    "\n",
    "# Creation of the dataset for the neural network training:\n",
    "validation_dataset = DatasetNNFBP(spheres_projections, spheres)\n",
    "\n",
    "# Saving of the dataset:\n",
    "validation_dataset.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "The random spheres:                                                  The 9 projections:\n",
    "\n",
    "<img src=\"data/gifs/random_spheres.gif\" width=\"300\"/>                              <img src=\"data/gifs/randspheres_proj.gif\" width=\"300\"/>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the neural network using the computed datasets. The network informations are automatically saved every 30s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\Admin-tomo\\\\Documents\\\\tomo-reconstruction-alix\\\\github_repository\\\\nn-tomo-reconstruction\\\\scripts\\\\data\\\\datasets_files\\\\rand7ellipses1024-full9th_rand7ellipses1024_bin.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Dataset retrieving using the ids\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m training_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetNNFBP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrand7ellipses1024-full9th_rand7ellipses1024_bin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m validation_dataset \u001b[38;5;241m=\u001b[39m DatasetNNFBP\u001b[38;5;241m.\u001b[39mretrieve(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandspheres1024-full9th_randspheres1024_bin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Number of hidden nodes in the network\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin-tomo\\anaconda3\\envs\\abtem_env\\Lib\\site-packages\\nntomo\\nnfbp.py:254\u001b[0m, in \u001b[0;36mDatasetNNFBP.retrieve\u001b[1;34m(clas, id)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the dataset in the folder dataset_files, given an provided id.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03m    DatasetSlices: The retrieved dataset.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    253\u001b[0m file_path \u001b[38;5;241m=\u001b[39m DATA_FOLDER \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets_files/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mid\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 254\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    255\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\Admin-tomo\\\\Documents\\\\tomo-reconstruction-alix\\\\github_repository\\\\nn-tomo-reconstruction\\\\scripts\\\\data\\\\datasets_files\\\\rand7ellipses1024-full9th_rand7ellipses1024_bin.pickle'"
     ]
    }
   ],
   "source": [
    "# Dataset retrieving using the ids\n",
    "training_dataset = DatasetNNFBP.retrieve(\"nnfbp[rand7ellipses1024-full9th][rand7ellipses1024]bin\")\n",
    "validation_dataset = DatasetNNFBP.retrieve(\"nnfbp[randspheres1024-full9th][randspheres1024]bin\")\n",
    "\n",
    "# Number of hidden nodes in the network\n",
    "Nh = 8\n",
    "\n",
    "# Training of NN-FBP\n",
    "network = nnfbp_training(training_dataset, validation_dataset, Nh, max_epoch=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstuctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computation of the reconstruction of the particule with 8 projections, using the network, and the SIRT algorithm. A quantitative comparison between NN-FBP and SIRT can then be made by computing the MSE loss of the reconstruction using a SIRT reconstruction with the 29 projections as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin-tomo\\anaconda3\\envs\\abtem_env\\Lib\\site-packages\\mrcfile\\mrcinterpreter.py:206: RuntimeWarning: Map ID string not found - not an MRC file, or file is corrupt\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "c:\\Users\\Admin-tomo\\anaconda3\\envs\\abtem_env\\Lib\\site-packages\\mrcfile\\mrcinterpreter.py:216: RuntimeWarning: Unrecognised machine stamp: 0x00 0x00 0x00 0x00\n",
      "  warnings.warn(str(err), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# The 29 projections stack of the MOF particule\n",
    "mof_projections_file = \"data/projection_files/HSH75-Pd-HAADF_hdr0.ali\"\n",
    "mof_29proj = ProjectionStack.from_mrc_file(mof_projections_file, 'tem')\n",
    "\n",
    "# The stack with a subset of 8 projections\n",
    "mof_8proj = mof_29proj.get_proj_subset(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of NN reconstruction.\n",
      "Reconstruction part 1/2: [████████████████████████████████████████████████████████████] 8/8 Est wait 00:0.010\n",
      "\n",
      "Reconstruction part 2/2: [████████████████████████████████████████████████████████████] 8/8 Est wait 00:0.090\n",
      "\n",
      "Saving volume...\n",
      "File saved at c:\\Users\\Admin-tomo\\Documents\\tomo-reconstruction-alix\\github_repository\\nn-tomo-reconstruction\\scripts\\data\\volume_files\\nn_rand7ellipses1024-full9th_rand7ellipses1024_bin_8h_HSH75-Pd-HAADF_hdr0-sub8.mrc. ID: nn_rand7ellipses1024-full9th_rand7ellipses1024_bin_8h_HSH75-Pd-HAADF_hdr0-sub8\n"
     ]
    }
   ],
   "source": [
    "# NN-FBP reconstruction for the 8 projections stack\n",
    "nn_reconstr_8proj = mof_8proj.get_NNFBP_reconstruction(network)\n",
    "nn_reconstr_8proj.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of SIRT reconstruction.\n",
      "Saving volume...\n",
      "File saved at c:\\Users\\Admin-tomo\\Documents\\tomo-reconstruction-alix\\github_repository\\nn-tomo-reconstruction\\scripts\\data\\volume_files\\sirt150_HSH75-Pd-HAADF_hdr0-sub8.mrc. ID: sirt150_HSH75-Pd-HAADF_hdr0-sub8\n"
     ]
    }
   ],
   "source": [
    "# SIRT reconstructions for the 8 projections stack, with 150 iterations\n",
    "sirt_reconstr_8proj = mof_8proj.get_SIRT_reconstruction(150)\n",
    "sirt_reconstr_8proj.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of SIRT reconstruction.\n",
      "Saving volume...\n",
      "File saved at c:\\Users\\Admin-tomo\\Documents\\tomo-reconstruction-alix\\github_repository\\nn-tomo-reconstruction\\scripts\\data\\volume_files\\sirt150_HSH75-Pd-HAADF_hdr0.mrc. ID: sirt150_HSH75-Pd-HAADF_hdr0\n"
     ]
    }
   ],
   "source": [
    "# SIRT reference reconstruction with 150 iterations\n",
    "sirt_reconstr_29proj = mof_29proj.get_SIRT_reconstruction(150)\n",
    "sirt_reconstr_29proj.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "The reference reconstruction,                  NN-FBP reconstruction (8 projections):                SIRT reconstruction (8 projections):\n",
    "SIRT with 29 projections:\n",
    "\n",
    "<img src=\"data/gifs/particule_sirt29.gif\" width=\"300\"/>            <img src=\"data/gifs/particule_nn8.gif\" width=\"300\"/>            <img src=\"data/gifs/particule_sirt8.gif\" width=\"300\"/>\n",
    "isosurface value: 190/255                          isosurface value: 245/255                          isosurface value: 170/255\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation and MSE computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation: all voxel values are set to 0 or 1, depending on a segmentation value. This value is set arbitrarily, by looking at the shape of the\n",
    "# volume in imod (isosurface value).\n",
    "nn_reconstr_8proj = nn_reconstr_8proj.get_segmented_volume(245/255)\n",
    "sirt_reconstr_8proj = sirt_reconstr_8proj.get_segmented_volume(170/255)\n",
    "sirt_reconstr_29proj = sirt_reconstr_29proj.get_segmented_volume(190/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN-FBP MSE: 0.0001929197460412979\n",
      "SIRT MSE: 0.0002627996727824211\n"
     ]
    }
   ],
   "source": [
    "# MSE computation\n",
    "print(f\"NN-FBP MSE: {get_MSE_loss(sirt_reconstr_29proj, nn_reconstr_8proj)}\")\n",
    "print(f\"SIRT MSE: {get_MSE_loss(sirt_reconstr_29proj, sirt_reconstr_8proj)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.125\n",
      "4096.0\n",
      "24.078125\n",
      "36.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cupy\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_allocated()/1024**2)\n",
    "print(torch.cuda.memory_reserved()/1024**2)\n",
    "print(cupy.get_default_memory_pool().used_bytes()/1024**2)\n",
    "print(cupy.get_default_memory_pool().total_bytes()/1024**2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abtem_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
