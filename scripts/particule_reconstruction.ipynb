{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A script to reconstruct a MOF particle from a subset of 8 projections from HSH75-Pd-HAADF_hdr0.ali (this code works for .mrc and .ali files), which originally is a stack of 29 projections between -70° and 70°.\n",
    "\n",
    "For an introduction on Python classes, see tutorial_classes.ipynb.\n",
    "For an introduction on how neural networks works, see https://www.3blue1brown.com/topics/neural-networks.\n",
    "For more details about the training procedure and the overall pytorch framework, see https://pytorch.org/tutorials/beginner/basics/intro.html.\n",
    "\n",
    "For more details about a particular function / method, see the specific documentation in the code.\n",
    "\n",
    "For more details about NN-FBP implementation, see the original article: Fast Tomographic Reconstruction from Limited Data Using Artificial Neural\n",
    "Networks, D. M. Pelt and al., 2013 (https://ieeexplore.ieee.org/document/6607157)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports ###\n",
    "from nntomo.utilities import get_MSE_loss\n",
    "from nntomo.network import model_training\n",
    "from nntomo.dataset_slices import DatasetSlices\n",
    "from nntomo.projection_stack import ProjectionStack\n",
    "from nntomo.volume import Volume\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "The original 29 projections from STEM measurements. The         A subset of 8 projections: a comparison will be made between\n",
    "SIRT reconstruction using all these projections will be         the NN-FBP and the SIRT reconstructions to evaluate the\n",
    "used as a reference for the real volume of the particule.       reconstruction performance for very small subsets of projections.\n",
    "\n",
    "<img src=\"data/gifs/particule_29proj.gif\" width=\"300\"/>                                  <img src=\"data/gifs/particule_8proj.gif\" width=\"300\"/>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, a stack of ellipses and its associated projections are used for the training dataset. The training dataset is used to modify the values of the weights and biases of the network, by comparing the predicted output of each input of the dataset and the real outputs. The projections are made with the ASTRA toolbox. The corresponding dataset is created and saved. See the pytorch tutorial for more information about the use of Dataset objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation of the ellipses: [████████████████████████████████████████████████████████████] 100/100 Est wait 00:0.0\n",
      "\n",
      "Saving volume...\n",
      "File saved at c:\\Users\\Admin-tomo\\Documents\\tomo-reconstruction-alix\\github_repository\\nn-tomo-reconstruction\\scripts\\data\\volume_files\\rand7ellipses1024.mrc. ID: rand7ellipses1024\n"
     ]
    }
   ],
   "source": [
    "# Generation of the ellipses\n",
    "ellipses_volume = Volume.stack_7ellipses(100, shape=1024, semi_axis_range=(20,200), padding=100)\n",
    "ellipses_volume.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset...\n",
      "File saved at c:\\Users\\Admin-tomo\\Documents\\tomo-reconstruction-alix\\github_repository\\nn-tomo-reconstruction\\scripts\\data\\datasets_files\\rand7ellipses1024-full9th_rand7ellipses1024_bin.pickle. ID: rand7ellipses1024-full9th_rand7ellipses1024_bin\n"
     ]
    }
   ],
   "source": [
    "# Creation of a volume object for the ellipses\n",
    "ellipses_volume = Volume.retrieve('rand7ellipses1024')\n",
    "\n",
    "# Creation of the projections (9 projections from -90° to 70°)\n",
    "ellipses_projections = ProjectionStack.from_volume(ellipses_volume, 9, 'full')\n",
    "\n",
    "# Creation of the dataset for the neural network training:\n",
    "training_dataset = DatasetSlices(ellipses_projections, ellipses_volume)\n",
    "\n",
    "# Saving of the dataset:\n",
    "training_dataset.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Each slice of the ellipses stack:                          The 9 projections taken around the axis perpendicular to the screen:\n",
    "\n",
    "<img src=\"data/gifs/ellipses.gif\" width=\"300\"/>              <img src=\"data/gifs/ellipses_proj.gif\" width=\"800\"/>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, random spheres are used for the validation set. The validation set is used to assess the performance of the network during the training phase on unknown data, and decide when to stop the training to avoid overfitting. The projections are also made with the ASTRA toolbox. The corresponding dataset is created and saved. See the pytorch tutorial for more information about the use of Dataset objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation of the spheres: [████████████████████████████████████████████████████████████] 60/60 Est wait 00:0.00\n",
      "\n",
      "Saving volume...\n",
      "File saved at c:\\Users\\Admin-tomo\\Documents\\tomo-reconstruction-alix\\github_repository\\nn-tomo-reconstruction\\scripts\\data\\volume_files\\randspheres1024.mrc. ID: randspheres1024\n"
     ]
    }
   ],
   "source": [
    "# Generation of the spheres\n",
    "spheres = Volume.random_spheres(60, shape=1024)\n",
    "spheres.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset...\n",
      "File saved at c:\\Users\\Admin-tomo\\Documents\\tomo-reconstruction-alix\\github_repository\\nn-tomo-reconstruction\\scripts\\data\\datasets_files\\randspheres1024-full9th_randspheres1024_bin.pickle. ID: randspheres1024-full9th_randspheres1024_bin\n"
     ]
    }
   ],
   "source": [
    "# Creation of a volume object for the spheres\n",
    "spheres = Volume.retrieve('randspheres1024')\n",
    "\n",
    "# Creation of the projections (9 projections from -90° to 70°)\n",
    "spheres_projections = ProjectionStack.from_volume(spheres, 9, 'full')\n",
    "\n",
    "# Creation of the dataset for the neural network training:\n",
    "validation_dataset = DatasetSlices(spheres_projections, spheres)\n",
    "\n",
    "# Saving of the dataset:\n",
    "validation_dataset.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "The random spheres:                                                  The 9 projections:\n",
    "\n",
    "<img src=\"data/gifs/random_spheres.gif\" width=\"300\"/>                              <img src=\"data/gifs/randspheres_proj.gif\" width=\"300\"/>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the neural network using the computed datasets. The network informations are automatically saved every 30s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of training.\n",
      "Epoch 1 (n=0)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.043904 \n",
      "\n",
      "Epoch 2 (n=0)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.018775 \n",
      "\n",
      "Epoch 3 (n=0)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.015384 \n",
      "\n",
      "Epoch 4 (n=0)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.013509 \n",
      "\n",
      "Epoch 5 (n=0)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.012931 \n",
      "\n",
      "Epoch 6 (n=0)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.012553 \n",
      "\n",
      "Data saved.\n",
      "Epoch 7 (n=0)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.013160 \n",
      "\n",
      "Epoch 8 (n=1)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.012370 \n",
      "\n",
      "Epoch 9 (n=0)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.012582 \n",
      "\n",
      "Epoch 10 (n=1)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.011679 \n",
      "\n",
      "Epoch 11 (n=0)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.012132 \n",
      "\n",
      "Epoch 12 (n=1)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.011299 \n",
      "\n",
      "Data saved.\n",
      "Epoch 13 (n=0)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.011788 \n",
      "\n",
      "Epoch 14 (n=1)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.011416 \n",
      "\n",
      "Epoch 15 (n=2)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.011164 \n",
      "\n",
      "Epoch 16 (n=0)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.011375 \n",
      "\n",
      "Epoch 17 (n=1)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.011128 \n",
      "\n",
      "Epoch 18 (n=0)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010625 \n",
      "\n",
      "Data saved.\n",
      "Epoch 19 (n=0)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.011287 \n",
      "\n",
      "Epoch 20 (n=1)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.011201 \n",
      "\n",
      "Epoch 21 (n=2)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010676 \n",
      "\n",
      "Epoch 22 (n=3)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010935 \n",
      "\n",
      "Epoch 23 (n=4)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010486 \n",
      "\n",
      "Data saved.\n",
      "Epoch 24 (n=0)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010160 \n",
      "\n",
      "Epoch 25 (n=0)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.012770 \n",
      "\n",
      "Epoch 26 (n=1)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.011309 \n",
      "\n",
      "Epoch 27 (n=2)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010089 \n",
      "\n",
      "Epoch 28 (n=0)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010838 \n",
      "\n",
      "Epoch 29 (n=1)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010342 \n",
      "\n",
      "Data saved.\n",
      "Epoch 30 (n=2)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010552 \n",
      "\n",
      "Epoch 31 (n=3)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.011199 \n",
      "\n",
      "Epoch 32 (n=4)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.011248 \n",
      "\n",
      "Epoch 33 (n=5)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.009956 \n",
      "\n",
      "Epoch 34 (n=0)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010210 \n",
      "\n",
      "Epoch 35 (n=1)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010327 \n",
      "\n",
      "Data saved.\n",
      "Epoch 36 (n=2)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010497 \n",
      "\n",
      "Epoch 37 (n=3)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010098 \n",
      "\n",
      "Epoch 38 (n=4)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010418 \n",
      "\n",
      "Epoch 39 (n=5)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010198 \n",
      "\n",
      "Epoch 40 (n=6)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010192 \n",
      "\n",
      "Epoch 41 (n=7)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.011201 \n",
      "\n",
      "Data saved.\n",
      "Epoch 42 (n=8)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.011208 \n",
      "\n",
      "Epoch 43 (n=9)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010734 \n",
      "\n",
      "Epoch 44 (n=10)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010087 \n",
      "\n",
      "Epoch 45 (n=11)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010028 \n",
      "\n",
      "Epoch 46 (n=12)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010524 \n",
      "\n",
      "Data saved.\n",
      "Epoch 47 (n=13)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010380 \n",
      "\n",
      "Epoch 48 (n=14)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.011223 \n",
      "\n",
      "Epoch 49 (n=15)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010357 \n",
      "\n",
      "Epoch 50 (n=16)\n",
      "-------------------------------\n",
      "Avg MSELoss(): 0.010776 \n",
      "\n",
      "End of training.\n"
     ]
    }
   ],
   "source": [
    "# Dataset retrieving using the ids\n",
    "training_dataset = DatasetSlices.retrieve(\"rand7ellipses1024-full9th_rand7ellipses1024_bin\")\n",
    "validation_dataset = DatasetSlices.retrieve(\"randspheres1024-full9th_randspheres1024_bin\")\n",
    "\n",
    "# Number of hidden nodes in the network\n",
    "Nh = 8\n",
    "\n",
    "# Training of NN-FBP\n",
    "network = model_training(training_dataset, validation_dataset, Nh, max_epoch=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstuctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computation of the reconstruction of the particule with 8 projections, using the network, and the SIRT algorithm. A quantitative comparison between NN-FBP and SIRT can then be made by computing the MSE loss of the reconstruction using a SIRT reconstruction with the 29 projections as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin-tomo\\anaconda3\\envs\\abtem_env\\Lib\\site-packages\\mrcfile\\mrcinterpreter.py:206: RuntimeWarning: Map ID string not found - not an MRC file, or file is corrupt\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "c:\\Users\\Admin-tomo\\anaconda3\\envs\\abtem_env\\Lib\\site-packages\\mrcfile\\mrcinterpreter.py:216: RuntimeWarning: Unrecognised machine stamp: 0x00 0x00 0x00 0x00\n",
      "  warnings.warn(str(err), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# The 29 projections stack of the MOF particule\n",
    "mof_projections_file = \"data/projection_files/HSH75-Pd-HAADF_hdr0.ali\"\n",
    "mof_29proj = ProjectionStack.from_mrc_file(mof_projections_file, 'tem')\n",
    "\n",
    "# The stack with a subset of 8 projections\n",
    "mof_8proj = mof_29proj.get_proj_subset(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of NN reconstruction.\n",
      "Reconstruction part 1/2: [████████████████████████████████████████████████████████████] 8/8 Est wait 00:0.010\n",
      "\n",
      "Reconstruction part 2/2: [████████████████████████████████████████████████████████████] 8/8 Est wait 00:0.090\n",
      "\n",
      "Saving volume...\n",
      "File saved at c:\\Users\\Admin-tomo\\Documents\\tomo-reconstruction-alix\\github_repository\\nn-tomo-reconstruction\\scripts\\data\\volume_files\\nn_rand7ellipses1024-full9th_rand7ellipses1024_bin_8h_HSH75-Pd-HAADF_hdr0-sub8.mrc. ID: nn_rand7ellipses1024-full9th_rand7ellipses1024_bin_8h_HSH75-Pd-HAADF_hdr0-sub8\n"
     ]
    }
   ],
   "source": [
    "# NN-FBP reconstruction for the 8 projections stack\n",
    "nn_reconstr_8proj = mof_8proj.get_NN_reconstruction(network)\n",
    "nn_reconstr_8proj.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of SIRT reconstruction.\n",
      "Saving volume...\n",
      "File saved at c:\\Users\\Admin-tomo\\Documents\\tomo-reconstruction-alix\\github_repository\\nn-tomo-reconstruction\\scripts\\data\\volume_files\\sirt150_HSH75-Pd-HAADF_hdr0-sub8.mrc. ID: sirt150_HSH75-Pd-HAADF_hdr0-sub8\n"
     ]
    }
   ],
   "source": [
    "# SIRT reconstructions for the 8 projections stack, with 150 iterations\n",
    "sirt_reconstr_8proj = mof_8proj.get_SIRT_reconstruction(150)\n",
    "sirt_reconstr_8proj.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of SIRT reconstruction.\n",
      "Saving volume...\n",
      "File saved at c:\\Users\\Admin-tomo\\Documents\\tomo-reconstruction-alix\\github_repository\\nn-tomo-reconstruction\\scripts\\data\\volume_files\\sirt150_HSH75-Pd-HAADF_hdr0.mrc. ID: sirt150_HSH75-Pd-HAADF_hdr0\n"
     ]
    }
   ],
   "source": [
    "# SIRT reference reconstruction with 150 iterations\n",
    "sirt_reconstr_29proj = mof_29proj.get_SIRT_reconstruction(150)\n",
    "sirt_reconstr_29proj.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "The reference reconstruction,                  NN-FBP reconstruction (8 projections):                SIRT reconstruction (8 projections):\n",
    "SIRT with 29 projections:\n",
    "\n",
    "<img src=\"data/gifs/particule_sirt29.gif\" width=\"300\"/>            <img src=\"data/gifs/particule_nn8.gif\" width=\"300\"/>            <img src=\"data/gifs/particule_sirt8.gif\" width=\"300\"/>\n",
    "isosurface value: 190/255                          isosurface value: 245/255                          isosurface value: 170/255\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation and MSE computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation: all voxel values are set to 0 or 1, depending on a segmentation value. This value is set arbitrarily, by looking at the shape of the\n",
    "# volume in imod (isosurface value).\n",
    "nn_reconstr_8proj = nn_reconstr_8proj.get_segmented_volume(245/255)\n",
    "sirt_reconstr_8proj = sirt_reconstr_8proj.get_segmented_volume(170/255)\n",
    "sirt_reconstr_29proj = sirt_reconstr_29proj.get_segmented_volume(190/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN-FBP MSE: 0.0001929197460412979\n",
      "SIRT MSE: 0.0002627996727824211\n"
     ]
    }
   ],
   "source": [
    "# MSE computation\n",
    "print(f\"NN-FBP MSE: {get_MSE_loss(sirt_reconstr_29proj, nn_reconstr_8proj)}\")\n",
    "print(f\"SIRT MSE: {get_MSE_loss(sirt_reconstr_29proj, sirt_reconstr_8proj)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.125\n",
      "4096.0\n",
      "24.078125\n",
      "36.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cupy\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_allocated()/1024**2)\n",
    "print(torch.cuda.memory_reserved()/1024**2)\n",
    "print(cupy.get_default_memory_pool().used_bytes()/1024**2)\n",
    "print(cupy.get_default_memory_pool().total_bytes()/1024**2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abtem_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
